# Кратко про Getl
Groovy ETL (Getl) - open source проект на Groovy, разработанный в 2012 году для автоматизации загрузки и обработки 
данных с разных источников в хранилища данных Vertica. 

Исходный код проекта располагается на [GitHub](https://github.com/ascrus/getl).
Русскоязычная документация располагается на [GitHub Pages](https://github.com/ascrus/getl). 

Изначально софт писался как замена Talend и других классических ETL для проектов, где требовалось быстро и много загружать
данные из разнообразных файловых источников с причудливыми форматами, с плавающей структурой, известной только на
момент захвата данных: ASN.1, CSV, XML, Json и т.д. с вложениями других форматов внутрь и прочими прелестями работы с данными
при автоматизации в телекоммуникационной отрасли. Помимо этого Getl решал задачу 
быстрой разработки пилотных проектов: считать структуру с РСУБД источников данных, создать таблицы с нужным типом полей
в ХД на Vertica, перелить данные в них с исходных таблиц, обеспечить расчеты аналитических витрин.

# Почему Groovy
Чтобы обеспечить баланс между простой разработки сценариев, гибкостью работы с плавающими структурами и скоростью работы
с данными, Getl был разработан на языке Groovy с использованием всех его достоинств: динамическая компиляция во время 
выполнения, статическая компиляция для ускорения выполнения нагруженных участков кода, поддержка разработки DSL расширений, 
управление видимостью объектов в коде замыканий, полная совместимость с кодом, написанным на Java, расширение языка 
для упрощения работы с массивами, jdbc источниками, временными типами и т.д. 
 
# Развитие за 8 лет
За последующие восемь лет Getl научился работать с инкрементальным захватом данных, с группами файлов на разных файловых 
системах, стал поддерживать язык хранимых процедур для разработки скриптов под Vertica и обзавелся 
и собственным специализированным DSL языком для работы с данными.

# Какие гвозди удобно забивать с помощью Getl
Getl полезен, если Вы разрабатываете проекты хранилищ данных Vertica и Вам требуется:
* Копировать массивы данных между разными JDBC и файловыми источниками;
* Обеспечить инкрементальный захват данных и загрузку изменений в ХД;
* Обрабатывать по заданным условиям файлы на файловых источниках;
* В рамках пилотного проекта взять все таблицы источника и их быстро перетащить в ХД;
* Упростить кодирование ETL процессов на среде разработки, среде тестирования и их работу на промышленной среде ХД.    

# Требования к тем, кто хочет работать на Getl
Для того, чтобы писать на Getl процессы ETL, достаточно базисно изучить две вещи:
1. Groovy, это можно сделать прямо на сайте "Хабрахабр" за 15 минут: [статья Groovy за 15 минут](http://habrahabr.ru/post/122127/).
1. Любой IDE, который поддерживает Java и Groovy и обеспечивает комфортную разработку и отладку кода, например 
[JetBrains IntelliJ IDEA](https://www.jetbrains.com/ru-ru/idea/documentation/) или 
[Eclipse](https://www.ibm.com/developerworks/ru/library/os-eclipse-platform/).
 
# Подключение Getl к проекту
Все просто: создайте gradle проект в Вашей IDE и пропишите в build.gradle ссылку на Getl: 
```groovy
dependencies {
    compile(group: 'net.sourceforge.getl', name: 'getl', version:'4.4.2')
}
```
* Getl выкладывается в Maven Central, поэтому указывать репозиторий не нужно.
* Getl уже содержит ссылки на все зависимые библиотеки, поэтому в проект будут подтянуты Groovy и остальные библиотеки, 
требуемые для его работы.

Для того, чтобы Getl видел Ваши РСУБД и Vertica, рекомендуется в проекте сделать директорию jdbc и скопировать туда
jar файлы используемых JDBC драйверов. А в gradle указать их подключение в проект для запуска и отладки проекта в IDE:
```groovy
dependencies {
    compile(group: 'net.sourceforge.getl', name: 'getl', version:'4.4.2')
    compile fileTree(dir: 'jdbc')
}
```
* Если проекту будет нужно использовать разные версии JDBC драйверов для разных источников и у них нет совместимости, 
то вместо копирования файлов таких драйверов, в Getl возможно уде при подключении соединения к РСУБД указать, какой именно
jar файл JDBC драйвера требуется использовать. 
    
 
# Использование в классах и скриптах Groovy
Для использования Getl в собственных классах Groovy достаточно использовать статический метод Dsl класса Getl. Внутри
кода Dsl доступны все функции Getl и можно разрабатывать любые сценарии:   
```groovy
package demo

import getl.lang.Getl
  
class GroovyApp {
    static void main(def args) {
      helloWorld()
    }

    void helloWorld() {
        Getl.Dsl {
            logInfo 'Привет мир!'
        }
    }
}
```
Вызов программы с командной строки будет такой же, как для любого Java приложения. Компилируем проект в jar файл с 
помощью Gradle и вызываем с указанием запускаемого класса:
```shell script
java -cp myproj.jar demo.GroovyApp
```
P.S. Не забудьте в class path (-cp) также добавить пути к jar файлам Getl и используемых Jdbc драйверов.

Я рекомендую не усложнять логику разработки ХД проектов на классах, а разрабатывать ETL/ETL процессы как скрипты (сценарии)
Groovy. Классы лучше использовать там, где требуется функциональность ООП (наследование, ОРМ, библиотеки статических 
функций и т. д.). Сценарий Getl выглядит так:
```groovy
// Файл GetlDemo.groovy
package demo

import groovy.transform.BaseScript
import getl.lang.Getl

@BaseScript Getl main

logInfo 'Привет мир!'
``` 
* Аннотация _BaseScript_ указывает Groovy, что этот скрипт будет выполняться c DSL расширением Getl. Переменная main при
работе скрипта будет содержать ссылку на экземпляр самого объекта Getl, под которым был запущен скрипт. 

Такой скрипт можно вызвать даже без компиляции с помощью Groovy, если он установлен в ОС. Для этого
нужно скопировать по пути инсталляции Groovy в директорию _libs_ все jar файлы, нужные для работы Getl, включая JDBC
драйвера. Далее можно прямо в ОС вызвать Getl скрипт из главной директории проекта:
```shell script
groovy demo/GetlDemo.groovy
```
Такой способ неплох, если требуется быстро что-то сделать и выполнить, а под рукой только командная строка, 
текстовый редактор или установленный Groovy Shell. Но для разработки полноценных проектов ХД это не тот путь
разработки, потому что:
1. Скрипты хранятся как набор текстовых файлов в директориях, с открытыми для просмотра параметрами подключений.
1. Усложняется вызов скриптов другими скриптами, нужно указывать корректный относительный путь между директориями пакетами.
1. У скриптов нет возможности хранить конфигурации и нужные для работы данные в ресурсных файлах.

В этом плане правильнее и выгоднее разрабатывать полноценный проект в IDE, запускать и тестировать процессы прямо там, 
а потом уже всё собирать в jar файл с указанием версии и его выкладывать для работы на промышленный стенд. Для запуска 
Groovy скриптов из jar файла в классе Getl реализован метод main для запуска приложений, которому можно в параметре _runclass_ передать, 
какой скрипт требуется запустить:   
```shell script
java -cp myproj.jar getl.lang.Getl runclass=demo.GetlDemo
``` 
P.S. Не забудьте в class path также добавить пути ко всем jar файлам, нужным для работы Getl, включая JDBC драйвера.

# Общий синтаксис сценариев Getl
Чтобы не ходить, вокруг, да около, ниже представляю схематический набросок сценария Getl в "полном" виде, а уже
далее по ходу статьи буду описывать что и чего означает и когда может быть использовано:
```groovy
package пакет

import groovy.transform.BaseScript
import groovy.transform.Field
import getl.lang.Getl

@BaseScript Getl main

// Входные параметры сценария, которые можно задать при его вызове
// например @Field Date beforeDate
@Field тип имя_параметра = значение_по_умолчанию  

// Инициализация работы сценария
void init() {
    // Управление конфигурацией
    configuration { 
        // Загрузить файл конфигурации из ресурсных файлов проекта
        load 'resource:/конфигурация.conf'
    }
 
    // Управление файлом лога сценария
    logging {
        logFileName = 'путь/процесс.log'
    }
}

// Проверка параметров сценария до его выполнения
void check() {
    assert имя_параметра != null, 'Надо указать параметр!'
}

// Вызывается, если во время работы сценария произошла ошибка
void error(Exception e) {
  logError "Произошла ошибка: ${e.message}"
}

// Финализация после работы сценария
void done() {
  // Удалить временные ресурсы, закрыть используемые соединения
}

// Вывод в лог сообщений
logInfo "Старт сценария"

// Вызов требуемых для работы других сценариев, при условии, что ранее они никем не вызывались 
// (например описание соединений и таблиц) 
callScripts пакет.ИмяСкрипта1, пакет.ИмяСкрипта2

// Описание соединения
verticaConnection('соединение', true) {
    // Считать параметры соединения с загруженной конфигурации
    useConfig 'конфигурация1'

    // Логировать все команды к Vertica, если сценарий вызван из класса тестирования
    ifUnitTestMode {
        sqlHistoryFile = 'путь/vertica.{date}.sql'
    }
    
    // Вызывать при подключении соединения к БД
    whenConnecting {
        executeCommand 'SET SEATCH_PATH TO demo, public;'
    }
}

// Описание таблицы 
verticaTable('vertica:table', true) {
    // Соединение для таблицы
    useConnection verticaConnection('соединение')
    // Нахождение таблицы в БД
    schemaName = 'demo'; tableName = 'table1'
    // Поля таблицы
    field('id') { type = integerFieldType; isKey = true }
    field('name') { length = 50; isNull = false }
    field('dt') { type = datetimeType; isNull = false }
    // Свойства таблицы
    createOpts {
        partitionBy = 'Year(dt) * 100 + Month(dt)'
        orderBy = ['dt', 'name']
        segmentedBy = 'Hash(id) ALL NODES'
    }
    // Методы таблицы
    create(ifNotExists: true)
}

// Если нужно отдельно профилировать блоки кусков логики
profile('Копирование из A в Б') {
    // Копирование с источника в приёмник
    copyRows(oracleTable('oracle:table'), verticaTable('vertica:table'))
    // Вызвать сценарий, передав ему параметром проверяемую таблицу
    callScript пакет.Проверка, { параметр1 = verticaTable('vertica:table') }
    // Выполнение SQL скриптов на источнике 
    sql(verticaConnection('соединение')) {
        vars.переменная1=значение // можно использовать в SQL скриптах
        runFile 'resource://script1.sql'
        if (vars.переменная2 == 'INVALID') // переменную можно установить в SQL скрипте и получить значение
            exec '''
                    IF (SELECT Count(*) FROM demo.table1) > 100;
                        FOR SELECT id AS category_id FROM demo.categories WHERE name = {переменная2};
                            DELETE FROM demo.table1 WHERE group_id = {category_id};   
                        END FOR;
                        COMMIT;
                    END IF;
                    '''
    }   
}

// Выполнение тестовых проверок
testCase {
    assertEquals(oracleTable('tableA').countRow(), verticaTable('tableB').countRow)
}
```
Из примера сразу видно, что:
1. Сценарии Getl могут иметь входные параметры, а значит можно разрабатывать повторно используемые шаблоны для разных 
классов задач.
1. Можно описать управляющую логику запуска-проверки-обработки ошибки-финализации сценария, обеспечив прозрачное 
разделение кода между служебной и бизнес логикой.
1. Есть возможность выносить параметры в конфигурации, которые могут храниться во внешних файлах или ресурсных файлах 
проекта, это полезно для разделения работы процессов на разных стендах и в разных условиях.
1. Можно записать все, что происходит, в лог файлы, что полезно при контроле и отладке.
1. Есть поддержка событийной модели, где можно определить ситуации и код, который их обрабатывает.
1. Поддерживается профилирование работы логики сценария, можно выявлять на тестовой и промышленной среде узкие места 
производительности.
1. В таблицах и файловых системах поддерживаются их специфические свойства и методы, которые позволяют более гибко
писать логику работы с ними. 
1. В языке сценариев реализованы операторы манипулирования данными между источниками и файловыми системами.
1. Внутри кода сценария или ресурсном файле можно писать параметризированные SQL скрипты, в которых есть поддержка
ветвления и циклов. Это бывает нужным при разработке логики расчета аналитических витрин для БД Vertica, у которой нет
собственного языка хранимых процедур. 
1. Для облегчения проверок бизнес логики и данных, в Getl добавлена поддержка GroovyAssert методов,
с помощью которых можно проверять состояние объектов, сравнивать с эталоном и т. д. Достаточно написать testCase и Ваш
код внутри GroovyAssert объекта.

# Работа с источниками
Getl поддерживает работу с большинством традиционных источников данных:
* JDBC источники: DB2, Firebird, GreenPlum, H2, Hive, Impala, MS SQLServer, MySQL, Netezza, NetSuite, Oracle, PostgreSQL, 
Vertica;
* Файловые форматы: CSV, Excel, Json, XML, Yaml;
* Облачные источники: SalesForce;

Для упрощения работы с прочими видами и форматами источников в Getl реализованы операторы записи и пакетной загрузки в таблицы
РСУБД, остается только на Java или Groovy написать парсинг входных данных файлов с нестандартными форматами.

## Копирование записей с источника в приёмник
Если у набора данных источника и приёмника совпадает набор полей по именованию, то выглядит все просто:
```groovy
// Объявляем таблицу Oracle
def oratab = oracleTable {
    useConnection oracleConnection { // Объявляем соединение Oracle и назначаем его таблице
        connectHost = 'oracle-host'; connectDatabase = 'oradb'
        login = 'user'; password = 'password'
    }
    schemaName = 'user'; tableName = 'table1'
}

// Объявляем таблицу Vertica
def vertab = verticaTable {
    useConnection verticaConnection { // Объявляем соединение Vertica и назначаем его таблице
        connectHost = 'vertica-host1'; connectDatabase = 'verdb'
        extended.backupservernode = 'vertica-host2,vertica-host3'
        login = 'user'; password = 'password'
    }
    schemaName = 'stage'; tableName = 'table1'
}

// Копируем все записи из Oracle в Vertica
copyRows(oratab, vertab)
```
* В коде описываются таблица источник с Oracle и таблица приёмник в Vertica, для каждой таблицы задается описание соединения.
* Для Vertica соединения отдельно указывается список дополнительных нод кластера, к которым подключиться, если основная нода
подключения будет недоступной.
* Вызывается копирование из источника в приёмник.

Что делает Getl в _copyRows_:
1. Проверяет существования таблиц;
1. Получает список полей таблиц из каталога БД;
1. Строит карту связи между полями источника и приёмника по их именам (без привязки к регистру);
1. Для копируемых полей проводит анализ совместимости типов и генерирует на Groovy код копирования с приведением типов;
1. Компилирует сгенерированный код Groovy в байт-код JVM и выполняет его.

В итоге получилось минимум кода, но максимум универсальности и производительности. Усложним задачу: требуется скопировать
данных всех таблиц Oracle с указанной схемы в схему Vertica, на лету создав таблицы по структуре исходных таблиц. Кода 
будет ненамного больше:
```groovy
def vercon = verticaConnection {
    connectHost = 'vertica-host1'; connectDatabase = 'verdb'
    extended.backupservernode = 'vertica-host2,vertica-host3'
    login = 'user'; password = 'password'
    schemaName = 'stage'
}

oracleConnection {
    connectHost = 'oracle-host'; connectDatabase = 'oradb'
    login = 'user'; password = 'password'
    
    retrieveDatasets(schemaName: 'user') { oratab ->
        def vertab = verticaTable {
            useConnection vercon
            tableName = oratab.tableName
            field = oratab.field
            field.each { f ->
                if (f.type == f.stringFieldType) f.length = f.length * 2 }
            drop(ifExists: true)
            create()
        }
        copyRows(oratab, vertab)
    }
}
```
* Создается соединение с Vertica, в нем указывается, что по умолчанию идет работа с таблицами в схеме _stage_.
* Создается соединение с Oracle, внутри него вызывается функция возврата списка таблиц схемы _user_.
* Полученный список Oracle таблиц перебирается по очереди, внутри кода создается описание таблицы Vertica.
* Для таблицы Vertica указывается то же имя и такие же поля, как у таблицы Oracle, для varchar полей длина умножается
на 2, чтобы в UTF-8 поместились текстовые значения. Таблица удаляется, если существовала и создается заново.
* По ранее описанному алгоритму копируются значения между таблицами.

P.S. Пояснения для тех, кто незнаком с Closure Groovy: при переборе списка в блок кода обработки передается значение списка.
По умолчанию этот параметр называется _it_, но для наглядности его можно переименовать и работать с ним в коде. Здесь
в _oratab_ передается таблица Oracle, а в _f_ передается поле таблицы Vertica. 

Усложним еще задачу: требуется скопировать данные в многопоточном режиме, так как при больших объемах поочередное копирование
не самый эффективный способ. Привожу код:
```groovy
verticaConnection('ver:con', true) {
    connectHost = 'vertica-host1'; connectDatabase = 'verdb'
    extended.backupservernode = 'vertica-host2,vertica-host3'
    login = 'user'; password = 'password'
    schemaName = 'stage'
}

def oracon = oracleConnection {
    connectHost = 'oracle-host'; connectDatabase = 'oradb'
    login = 'user'; password = 'password'
}
    
thread {
    useList oracon.retrieveDatasets(schemaName: 'user')
    run(10) { element ->
        def oratable = element.cloneDatasetConnection()
        def vertab = verticaTable {
            useConnection verticaConnection('ver:con')
            tableName = oratab.tableName
            field = oratab.field
            field.each { f ->
                if (f.type == f.stringFieldType) f.length = f.length * 2 }
            drop(ifExists: true)
            create()

            writeOpts {
                batchSize = 10000
            }

        }
        copyRows(oratab, vertab)
    }
}
```
* Вместо создания соединения Vertica в локальную переменную мы зарегистрировали соединение в репозитории под именем 
_ver:con_. Это сделано не просто так: при регистрации объекта Getl в репозитории к нему можно обращаться из других 
сценариев проекта по его имени, а при обращении к нему из кода потока такой объект автоматически клонируется в отдельный
экземпляр для потока. Если бы мы создали соединение в локальную переменную и попытались бы его использовать внутри кода
потока, то получили бы ошибку JDBC драйвера Vertica, что под одним соединением идет попытка выполнения запросов в разных
потоках. В этом же примере при копировании записей в таблицы Vertica, для каждого потока будет автоматически создаваться
собственное соединение и закрываться после завершения работы потока.
* В _thread_ мы объявляем, кто код будет выполняться в многопоточном режиме, задаем список элементов для обработки в потоках в 
_useList_ и указываем код работы потока в run, передав параметром количество одновременно работающих потоков.
* Код внутри _run_ вызывается в отдельном от главного потоке, ему параметром передается обрабатываемый элемент списка. 
Стоит помнить про правила безопасной работы в потоках для кода Java/Groovy, не обращаться к переменным снаружи и не работать 
с JDBC соединениями, объявленными в главном потоке приложения. Так как список таблиц Oracle был получен в главном потоке,
то _element_ требуется клонировать вместе с соединением в локальный объект потока с помощью метода _cloneDatasetConnection_.
* При объявлении локальной переменной для таблицы Vertica, в качестве соединения для неё указывается соединения из репозитория.
Getl это увидит и автоматически клонирует соединение в новую сессию для потока. Таким образом при копировании в сценарии
таблиц в 10 потоков у Vertica будет одновременно подключены 11 сессий - одна главного потока и 10 текущих работающих потоков.
* Для таблицы Vertica выставлена опция размера пакетной вставки в 10 тысяч записей (по умолчанию 500). Это сделано для 
ускорения записи в таблицу. Getl будет буферизировать получаемые из Oracle записи в память и скидывать их пакетами 
(механизм jdbc prepared statement) в таблицу Vertica по 10 тысяч, что значительно ускорит запись на этот сервер. 
Здесь стоит помнить про размер выделенной памяти Вашему приложению, в которой надо хранить буферизированные записи. 

При копировании данных большого объема в Vertica, не выгодно использовать логику копирования пакетными
вставками, даже если указать буферизировать миллион записей, прироста скорости наблюдаться не будет большого, наоборот,
при таких объемах ресурсы начнет занимать сборщик мусора Java, который заинтересуется, а кому это нужно столько памяти.
В таких случаях выгоднее использовать пакетную загрузку CSV файлов Vertica, которая позволяет с космической скоростью
загружать большие массивы данных. Вы можете на Getl написать код сценария, в котором выгрузите сначала все таблицы
Oracle в CSV, а потом загрузите все CSV в Vertica. А во многих случаях можете этого не писать, Getl все сделает сам,
достаточно в _copyRows_ задать параметры поведения копирования:
```groovy
copyRows(oratab, vertab) {
    bulkLoad = true
    bulkAsGZIP = true
}
```
Что произойдет в таком случае:
1. Таблица Oracle будет выгружена во временный CSV файл, упакованный алгоритмом GZIP во временную директорию ОС. Здесь
стоит озадачиться, достаточно ли будет там места и при необходимости переназначить при запуске Вашего приложения 
temp для java.
1. После выгрузки с помощью COPY FROM LOCAL полученный файл будет загружен в Vertica и файл удалён.

# Чтение и запись в источники данных
Getl умеет читать данные со всех источников и записывать в JDBC источники и CSV файлы. Для разных источников есть разные 
ограничения: например, нельзя вставить записи в Hive или Impala таблицы (ибо ну очень медленно), зато туда спокойно можно
загрузить записи с помощью поддерживаемой в Getl пакетной загрузки CSV файлов.

Продемонстрирую пример записи в таблицу Vertica на базе случайно генерируемых данных:
```groovy
def vercon = verticaConnetion {
    connectHost = 'vertica-host1'; connectDatabase = 'verdb'
    extended.backupservernode = 'vertica-host2,vertica-host3'
    login = 'user'; password = 'password'
    schemaName = 'stage'

    executeCommand 'CREATE SEQUENCE IF NOT EXISTS stage.s_sales INCREMENT BY 1000;'
}

def seq = sequence {
    useConnection vercon
    name = 'stage.s_sales'
    cache = 1000
}

verticaTable {
    useVerticaConnection vercon 

    tableName = 'random_data'
    field('id') { type = integerFieldType; isKey = true }
    field('name') { length = 50; isNull = false }
    field('dt') { type = datetimeType; isNull = false }
    field('value') { type = numericFieldType; length = 12; precision = 2 }
    if (!exists) create()

    rowsTo {
        destParams.batchSize = 10000
        writeRow { add ->
            (1..10000).each {
                def row = [:]
                row.id = seq.nextval()
                row.name = GenerationUtils.GenerateString(50)
                row.dt = GenerationUtils.GenerateDateTime()
                row.value = GenerationUtils.GenerateNumeric(12, 2)

                add row
            }
        }
    }   
}
```
* В сценарии создается счетчик, который используется при заполнении таблицы данными. Таким образом, при каждом вызове
сценария, будет вставляться новая порция 10 тысяч случайно сгенерированных записей с уникальным ключом _id_.
* Размер кэша в счетчике указывает, с каким шагом выдаются номера в БД. Это позволяет снизить поток запросов на получение
нового номера счетчика, Getl при выдаче будет автоматически вести счетчик и при достижении номерного пула получать с БД
новое значение.
* Оператор _rowsTo_ вызываем блок записи в указанную таблицу. В данном примере он вызывается внутри кода таблицы, поэтому
ему не требуется указывать параметром, в какую таблицу будут записываться данные. 
* Вместо указания _batchSize_ в свойствах записи таблицы _writeOpts_, свойства можно указать для частного случае для
оператора записи с помощью _destParams_ (актуально и для copyRows).
* В _writeRow_ описывается код записи данных, в него параметром приходит объект записи в таблицу, при вызове которого
нужно передать запись.
* В Getl есть библиотека GenerationUtils, с помощью которой можно маскировать данные и генерировать случайные значения по
заданным правилам. Полезная штука для создания наборов данных для тестирования логики.
P.S. Как и для _copyRows_, в _rowsTo_ можно включить пакетную загрузку через промежуточный CSV файл опцией bulkLoad. 

Для чтения записей у таблиц есть функции _rows_ и _eachRow_. Запишем данные из полученной таблицы Vertica в Json и CSV файлы с применением
этих функций, выбрав по условию id меньше 1000:
```groovy
verticaTable { vertab ->
    useVerticaConnection vercon
    
    def csv = csv {
        fileName = '/data/files/file1.txt'
        fieldDelimiter = ';'
        codePage = 'utf-8' 
    }

    rowsTo(csv) {
        writeRow { writer ->
            vertab.eachRow(where: 'id < 1000', order: ['id']) { row ->
                writer row
            }
        }
    }

    def writer = new File('/data/files/file1.json').newWriter('utf-8')
    def builder = new StreamingJsonBuilder(writer)
    builder(vertab.rows(where: 'id < 1000', order: ['id']))
    writer.close()
}
```
* При объявлении файловых источников в Getl можно не указывать соединение с помощью _useConnection_, если в имени файла 
_fileName_ прописано не только имя файла, но и путь.
* При указании параметров фильтрации _where, сортировки _order_ и количества возвращаемых записей _limit_, Getl транслирует
их в генерируемый для JDBC источников SELECT и использует возможности СУБД.
* Для записи в Json файл используется штатный билдер генерации Json, встроенный в Groovy. Аналогично есть билдеры для
генерации XML и Yaml файлов.

# Копирование файлов
Getl поддерживает работу со следующими файловыми системами: локальные, FTP, SFTP, HDFS. Можно копировать, перемещать, 
удалять и парсить группы файлов по заданным маскам пути и условиям.

Рассмотрим пример, где на FTP выкладываются CSV файлы по суточным директориям. Требуется копировать выявленные новые
файлы на локальную файловую систему и загружать их в таблицу Vertica:
```groovy
useVerticaConnection verticaConnetion('ver:con', true) {
    connectHost = 'vertica-host1'; connectDatabase = 'verdb'
    extended.backupservernode = 'vertica-host2,vertica-host3'
    login = 'user'; password = 'password'
}

verticaTable('data', true) {
    schemaName = 'stage'
    tableName = 'table1'
    assert exists, "В БД не найдена таблица $fullTableName!"
}

verticaTable('history', true) {
    schemaName = 'stage'
    tableName = 's_history_table1'
}

ftp('source', true) {
    server = 'ftp.domain'
    rootPath = '/files'
    login = 'user'; password = 'password'
    useStory verticaTable('history')
    createStory = true
}

files('dest', true) {
    rootPath = '/data/files/from_load'
}

fileCopier(ftp('source'), files('dest')) {
    useSourcePath {
        mask = '{date}/data_{region}.{num}.txt'
        variable('date') { type = dateFieldType; format = 'yyyyMMdd' }
        variable('num') { type = integerFieldType; length = 3 }
    }

    useDestinationpath {
        mask = '{region}/{date}'
    }

    numberAttempts = 3
    timeAttempts = 2
    order = ['date', 'num']
}

csv('bulk_file', true) {
    useConnection csvConnection { path = files('dest').rootPath }
    fieldDelimiter = '|'
    codePage = 'utf-8'
    field = verticaTable('data').field
}

verticaTable('data') {
    bulkLoadCsv(csv('bulk_file')) {
        files = filePath {
            mask = '{date}/data_{region}.{num}.txt'
            variable('date') { type = dateFieldType; format = 'yyyyMMdd' }
            variable('num') { type = integerFieldType; length = 3 }
        }
 
        loadAsPackage = true
        orderProcess = ['date', 'num']

        exceptionPath = csv('bulk_file').currentCsvConnection.path + '/vertica.bulkload.err'
        rejectedPath = csv('bulk_file').currentCsvConnection.path + '/vertica.bulkload.err'
        
        removeFile = true
    }
}
``` 
* В данном примере все объекты регистрируются в репозитории.
* Для того, чтобы каждый раз не задавать соединение при создании таблиц, используется оператор _useVerticaConnection_. 
При описании таблиц Vertica они будут автоматически работать на заданном соединении, если только для них явно не задано в
описании использовать другое соединение.
* В Vertica описывается таблица хранения данных и проверяется, что она есть в БД (свойство fullTableName вернет полное имя
таблицы в БД с учетом её схемы). Так же описывается таблица хранения истории скопированных файлов, она будет создана 
автоматически Getl при вызове копирования.
* Создается описание 2 файловых систем: источника на ftp с указанием таблицы хранения истории захвата данных и приёмника
на локальной файловой системе.
* _fileCopier_ отвечает за процесс копирования данных. При вызове передаются параметры источника и приёмника файловой 
системы (фс), задается маска захвата файлов, маска конечного расположения скопированных файлов в директориях от рутового 
пути приёмника, порядок копирования файлов и количество попыток при сбоях операций работы с фс.
* Для пакетной загрузки файлов в таблицы Vertica для них реализован метод _bulkLoadCsv_. При его вызове параметром указывается
CSV, который будет использован как шаблон загрузки (настройки, список полей, путь соединения). В _files_ можно задать
имя файла, список имен файлов, простую маску файлов или путь файлов с помощью _filePath_ объекта Getl (этот же тип используется
и при указании sourcePath и destinationPath в _fileCopier_). Опция _loadAsPackage_ указывает, что все найденные файлы
будут загружены одним вызовом COPY в Vertica с перечислением имен файлов. Если её отключить, то для каждого найденного
файла будет вызван свой COPY. Дополнительно указываются пути, в какие директории писать файлы ошибок для записей,
которые не прошли проверку Vertica на корректность. По окончании загрузки, исходные файлы будут удалены, 
так как включена опция _removeFile_.

В итоге, при вызове сценария, Getl просмотрит на ftp все директории, которые по имени могут быть распарсены в дату,
создаст на локальной фс нужную иерархию директорий, раскидает по ней файлы и одним запросом загрузит все файлы в 
Vertica. Несмотря на простоту, _fileCopier_ поддерживает множество режимов работы, в том числе зеркальное копирование 
на несколько источников одновременно или сегментное копирование на несколько источников по заданному хэш ключу. 
Последнее позволяет из одного источника взять файлы, раскидать их равномерно веером по кластеру ETL серверов и 
на каждом запустить свою обработку доставленных данных. Таким способом можно организовать распределенную обработку файлов.      

# Парсинг файлов
Организовать многопоточный парсинг файлов из источника не более сложно, чем их копировать. В примере нам потребуется
захватить из sftp источника json файлы по заданным условиям и записать их в Vertica. Усложним задачу тем, что в json
есть подчиненная структура "детализация", которую нужно сохранить в отдельную таблицу, то есть реализовать master-detail
схему: 
```groovy
useVerticaConnection verticaConnetion('ver:con', true) {
    connectHost = 'vertica-host1'; connectDatabase = 'verdb'
    extended.backupservernode = 'vertica-host2,vertica-host3'
    login = 'user'; password = 'password'
}

verticaTable('master', true) {
    schemaName = 'stage'
    tableName = 'master_table'
    assert exists, "В БД не найдена таблица $fullTableName!"
}

verticaTable('detail', true) {
    schemaName = 'stage'
    tableName = 'detail_table'
    assert exists, "В БД не найдена таблица $fullTableName!"
}

sftp('source', true) {
    server = 'ftp.domain'
    rootPath = '/files'
    login = 'user'; password = 'password'
    hostKey = 'ключ RSA'
}

json('source-file', true) {
    rootNode = 'data'
    field('id') { type = integerFieldType }
    field('dt') { type = datetimeFieldType; alias = 'datetime' }
    field('details') { type = objectFieldType }
}

fileProcessing(sftp('source')) {
    useSourcePath {
        mask = '{date}/data.{num}.json'
        variable('date') { type = dateFieldType; format = 'yyyyMMdd' }
        variable('num') { type = integerFieldType; length = 3 }
    }

    removeFiles = true
    removeEmptyDirs = true
    countOfThreadProcessing = 16
    threadGroupColumns = ['date']
    order = ['num']

    processFile { inf ->
        logFine "Парсинг файла ${inf.filepath}/${inf.filename} ..."
        json('source-file') {
            currentJSONConnection.path = inf.file.parent
            fileName = inf.file.name
        }

        copyRows(json('source-file'), verticaTable('master')) {
            childs(verticaTable('detail')) {
                writeRow { add, source_row ->
                    source_row.details?.each { elem ->
                        add master_id: source_row.id, value: elem.value 
                    }
                }
            }
        }

        copyRow { source_row, dest_row ->
            assert source_row.id != null
        }

        inf.result = inf.completeResult
        logInfo "Из файла ${inf.filepath}/${inf.filename} загружено ${verticaTable('master').updateRows} " +
                "записей в master и ${verticaTable('detail')} записей в detail."
    }
}
```
* Для sftp требуется указать RSA ключ подключения в _hostKey_ или задав имя файла ключей в _knownHostsFile_. Для 
источника не указана таблица истории, если в ней появятся файлы с такими же именами, они снова будут загружены.
* В описании json файла указывается главная нода, с которой брать массив данных. Если в json данные сразу лежат в массиве
без именования ноды, то в _rootNode_ нужно поставить точку. По умолчанию для json, xml и yaml файлов Getl пытается
считывать значения полей из тех аналогичных имен нод в файлах, поэтому имена полей должны быть указаны с _field_
с учетом регистра. Если имя определяемого поля не совпадает с именем ноды в файле или же требуется задать путь получения 
поля (например поле находится в "группе.аттрибуте"), то точный способ получения нужно указать в _alias_. Так как поле
details в json файле является сложной структурой (массивом), то ему задается объектный тип. Парсинг таких полей возлагается
на код сценария.
* Для _fileProcessing_ указывается источник файлов и маска поиска. В примере задано удалять файлы и пустые директории, если
с них удалились файлы при захвате. В _countOfThreadProcessing_ задано парсить файлы в 16 одновременных потоков, группируя
файлы по датам, что задано в параметр _threadGroupColumns_. При парсинге задан порядок сортировки, однако он условный,
так как файлы будут обрабатываться в многопоточном режиме: гарантируется только, что на момент запуска парсера список для обработки
файлов будет отсортирован.
* Свой код для парсинга найденного файла в потоке указывается в _processFile_. На вход ему приходит дескриптор, в котором
определены атрибуты файла, есть ссылка на скаченный с источника в локальную временную директорию файл и ожидается, что по
окончании работы код в _result_ установит, с каким результатом завершилась обработка файлов.
* При процессинге json файлу устанавливается, по какому пути находится файл для обработки и как он называется. Как и говорилось
выше, этот json файл не является экземпляром описанного выше объекта в репозитории _source-file_, а является его клоном 
в потоке. Поэтому можно смело менять его атрибуты внутри потока, это никак не отразиться на объект в репозитории и на
работу других потоков.
* В _copyRows_ копируются совпадающие по именам поля из json файла в основную таблицу Vertica. Дополнительно в _childs_
задается, что так же требуется писать данные в детальную таблицу Vertica. На каждую запись источника Getl будет вызывать
код _writeRow_ дочернего приёмника. В код передается дескриптор записи в дочернюю таблицу и исходная запись источника.
Остается только перебрать массив, который лежит в json поле details и сохранить его значения в таблицу, подставляя еще
код мастер записи. Конструкция "source_row.details?.each" указывает Groovy, что нужно выполнить перебор записей только,
если поле details не имеет "null" значение. В Java нам пришлось бы писать условие "if (source_row.details != null)". 
* Если указан код _copyRow_, то он будет вызываться на каждую запись источника. В код будет приходить два параметра:
запись источника и подготовленные для записи данные приёмника. В данном случае мы ничего не меняем в значениях для
записи полей таблицы мастер, а проверяем, что нужные поля точно заполнены. В случае ошибки в assert, будет считаться,
что обработка файла завершена с ошибкой. 
* В зависимости от того, какое результат указан в _result_, Getl будет производить разный набор действий:
    * Для completeResult файл будет считаться успешно обработанным. Он будет перенесен в файловую системе хранения архивных файлов, 
    если она задана в _storageProcessedFiles_. Если включено _removeFiles_, то файл будет удален с источника.
    * для errorResult файл будет считаться ошибочным. Он будет перенесен в файловую систему хранения ошибочных файлов,
    если она задана в _storageErrorFiles_. Вместе с файлом рядом будет создан текстовый файл с описанием ошибки и 
    трассировкой его выполнения на момент ошибки. Удаляться на источнике файл не будет. Если включено _removeFiles_, 
    то файл будет удален с источника.
    * Для ignoreResult файл будет считаться игнорируемым. Он никуда не будет переноситься и не будет удаляться с источника.

При запуске сценария Getl с sftp получит список подходящих файлов, сгруппирует их по директориям и по очереди каждую обработает,
запуская код обработки файлов в 16 потоков. Для каждого найденного файла в Vertica будет создано отдельное соединение,
запущена транзакция, будут записаны данные в 2 таблицы и соединение закрыто. Все успешно обработанное будет удалено,
включая суточные директории на источнике.

# Расширения в Getl под Vertica
Бывают момент, когда требуется в витринах произвести перерасчет данных за период задним числом. Если это делать прямо
на рабочей витрине, то придется столкнуться с множеством проблем: удалить старые данные партицией нельзя,
иначе пользователи просто не увидят старых данных, пока не посчитаются новые и не сохраняться в транзакции. А удалять
с помощью оператора DELETE миллионы или миллиарды записей в Vertica приведет к большому времени выполнения такого оператора
и деградации работы SELECT с этой таблицей, пока не будет выполнен _purge_ после перерасчета витрины. Функция обмена партициями
идеально решает все эти проблемы, при условии, что периоды вписываются в таблице партициями:
```groovy
verticaTable('marts:dm1', true) {
    schemaName = 'marts'
    tableName = 'dm1'
}

verticaTable('#temp_dm1', true) {
    schemaName = 'stage'
    tableName = 'dm1'
    createLike verticaTable('marts:dm1'), true, true
    truncate()
}

// Код расчета периода витрины задним числом в стейджинговой области
/* ... */

verticaTable('marts:dm1') {
    swapPartitionsBetweenTables('начало периода', 'конец периода', verticaTable('#temp_dm1'))
    purgeTable()
    analyzeStatistics()
} 
```
* В сценарии мы описываем в репозитории временную таблицу в стейджинговой области, задав имени в репозитории решетку. 
После выполнения сценариев Getl автоматически удаляет все объекты, имена которых начинаются с решетки. Это позволяет 
создавать временные объекты в репозитории и гарантировать, что они перестанут существовать после финиша работы их владельца
и имена не пересекутся при повторном вызове этого сценария или в других сценариях. Функция createLike создаст полную копию
структуры таблицы из указанной витрины, включая правила партиционирования и весь список проекций у таблицы родителя. 
Таблица будет создана, если её ещё не существует. Функция _truncate_ гарантирует, что таблица будет пустой на момент выполнения.
* Вызов функции _swapPartitionsBetweenTables_ поменяет местами партиции между витриной и стейджинговой таблицей. После
её выполнения в витрине окажутся новые рассчитанные данные, а в стейджинговой таблице старые данные до расчета.
* После изменения большого объема данных будет не лишним у витрины Vertica вызывать дефрагментацию с помощью _purgeTable_
и обновить статистику по таблице с помощью _analyzeStatistics_.

У Vertica есть функции быстрого копирования данных между кластерами: _COPY FROM VERTICA_ и _EXPORT TO VERTICA_. Для облегчения
работы с этими функциями в SQL, Getl поддерживает подключение одного кластера Vertica к другому:
```groovy
verticaConnection('stand1', true) {
    connectHost = 'vertica-stand1'; connectDatabase = 'db1'
    login = 'user'; password = 'password'
}

verticaConnection('stand2', true) {
    connectHost = 'vertica-stand2'; connectDatabase = 'db2'
    login = 'user'; password = 'password'
}

verticaConnection('stand1') {
    attachExternalVertica verticaConnection('stand2')
    executeCommand 'COPY public.table1 FROM VERTICA public.table1' 
    detachExternalVertica verticaConnection('stand2')
}
``` 
* К соединению _stand1_ будет подключено внешнее соединение с _stand2_ и оттуда скопированы записи таблицы.
* Getl запоминает, какие внешние подключения были связаны с соединением Vertica. Не удастся второй раз присоединить тот же
кластер Vertica или разъединить не присоединенный ранее кластер.

Для оптимизации работы с Vertica полезно периодически проводить дефрагментацию таблиц, у которых высокий процент удаленных
записей, а также пересчитывать статистику. Getl позволяет упростить этот процесс и написать свой небольшой сценарий:
```groovy
verticaConnection {
    connectHost = 'vertica-host1'; connectDatabase = 'verdb'
    extended.backupservernode = 'vertica-host2,vertica-host3'
    login = 'user'; password = 'password'

    purgeTables(15)
    analyzeStatistics()
}
``` 
* _purgeTables_ сделает дефрагментацию всех таблиц БД Vertica, у которых процент удаленных записей от общего количества 
превышает 15%.
* _analyzeStatistics_ пересчитает статистику всех таблиц в БД Vertica.

В Vertica работает анализатор выполняемых запросов, задача которого идентифицировать проблемы, и записывать советы по их
решению в специальную служебную таблицу. Часть из них касается устаревания статистики по таблицам, где оптимизатор
из-за этого может начать использовать не самые оптимальные запросы работы с данными. Getl умеет находить такие рекомендации
и обновлять статистику у тех таблиц, о которых упомянул анализатор Vertica:
```groovy
verticaConnection {
    connectHost = 'vertica-host1'; connectDatabase = 'verdb'
    extended.backupservernode = 'vertica-host2,vertica-host3'
    login = 'user'; password = 'password'

    def problems = analyzeWorkload(new Date())
    processWorkload problems
}
```
* _analyzeWorkload_ запустит анализатор Vertica и попросит начиная с текущего времени проанализировать все проблемы по
таблицам профилирования запросов.
* _processWorkload_ пройдется по списку найденных проблем и пересчитает статистику для таблиц, которые указал анализатор.

# Работа со стендами
С помощью конфигураций в Getl можно упростить разработку, тестирование и работу проекта на разных стендах. В Getl
поддерживается GroovySlurper формат конфигураций. Фактически это Groovy DSL язык конфигураций, в котором Вы можете
указывать не только значения, но и Groovy выражения:
```groovy
раздел {
    массивы {
        a = [1,2,3]
        b = [4,5]
        c = a + b
    }
    d = new Date()
    e = 'Текущая дата'
    f = "$e: $d"
}
```
С помощью ключевого слова _environments_ в конфигурации можно разделить хранения информации по разным средам. Напишем
конфигурацию подключения к дев и прод стенду Vertica и сохраним как ресурсный файл _/data/vertica.connect.conf_:
```groovy
environments {
    dev {
        connections {
            con1 {
                connectHost = 'vertica-dev-host1'; connectDatabase = 'verdb'
                extended {
                    backupservernode = 'vertica-dev-host2,vertica-dev-host3'
                }
                login = 'user'; password = 'password'
            }   
        }
    }

    prod {
        connections {
            con1 {
                connectHost = 'vertica-prod-host1'; connectDatabase = 'verdb'
                extended {
                    backupservernode = 'vertica-prod-host2,vertica-prod-host3'
                }
                login = 'user'; password = 'password'
            }   
        }
    }
}
```
Напишем сценарий создания подключения к Vertica _data.ConnectToVertica_:
```groovy
package data

import groovy.transform.BaseScript
import groovy.transform.Field
import getl.lang.Getl

@BaseScript Getl main

configuration {
    load 'resource:/data/vertica.connect.conf'
}

verticaConnection('ver:con', true) {
    useConfig 'con1'
}
```
* _useConfig_ указывает объекту Getl, что его свойства нужно взять из загруженной конфигурации. Для соединений параметры
нужно описывать в разделе _connections_ конфигураций, для файловых источников в разделе _files_.

Напишем ETL процесс работы со сценарием подключения
```groovy
package data

import groovy.transform.BaseScript
import groovy.transform.Field
import getl.lang.Getl

@BaseScript Getl main

callScripts data.ConnectToVertica

verticaConnection('ver:con') {
    // Подключение будет к нужному стенду
}
```
* При вызове этого сценария из командной строки, он по умолчанию будет работать в _prod_ среде. При чтении файла конфигурации
будет читаться раздел environments.prod. 
* При вызове этого сценария из-под unit test класса в IDE, он по умолчанию будет работать в _dev_ среде и подключаться 
к стенду разработки.
* Можно явно указать при вызове сценария, в какой среде работать, с помощью параметра командной строки _environment=<среда>_.

Для процессов работы с JDBC источниками часто бывает необходимо использовать разные логины в ходе работы сценариев.
Для этого можно описать логины и пароли пользователей в раздельном разделе конфигурации. Создадим конфигурацию
в ресурсном файле _/data/vertica.logins.conf_:
```groovy
logins {
    vertica {
        user1 = 'password1'
        user2 = 'password2'            
    }
}
```
Подключим этот файл в сценарий описания соединения _data.ConnectToVertica_:
```groovy
package data

import groovy.transform.BaseScript
import groovy.transform.Field
import getl.lang.Getl

@BaseScript Getl main

configuration {
    load 'resource:/data/vertica.connect.conf'
    load 'resource:/data/vertica.logins.conf'
}

verticaConnection('ver:con', true) {
    useConfig 'con1'
    loginsConfigStore = 'logins.vertica'
}
```
* При загрузке конфигураций Getl их объединяет в памяти. Если параметры нового файла перекрывают существующие, то 
они будут установлены поверх текущих значений.
* _loginsConfigStore_ указывает соединению, что в указанном разделе хранятся логины и пароли пользователей, разрешенные
для использования. Если такого раздела не будет в конфигурации, то будет сгенерирована ошибка.     

Теперь можно использовать переключение между пользователями Vertica в сценариях:
```groovy
package data

import groovy.transform.BaseScript
import groovy.transform.Field
import getl.lang.Getl

@BaseScript Getl main

callScripts data.ConnectToVertica

verticaConnection('ver:con') {
    useLogin 'user1'
    // Код работы под логином user1 ...
    useLogin 'user2'
    // Код работы под логином user2 ...
}
```
* _useLogin_ переключит соединение на указанного пользователя, взяв его пароль из установленного списка пользователей 
для соединения.
* При переключении между логинами текущее соединение будет разорвано и создано под новым пользователем.
* Если заданного имени пользователя в определенном для соединения списке логинов нет, то будет сгенерирована ошибка. 

# Разработка кейсов тестирования
Для разработки юнит тестов в Getl есть специальный класс _GetlDslTest_. Создадим в тестовом модуле проекта класс 
тестирования сценария proc.Proc1, очистив перед его запуском все таблицы в схеме _demo_ и проверив, что в этих таблицах
появились записи после работы сценария:
```groovy
package proc

import getl.test.GetlDslTest
import org.junit.Test

class Proc1Test extends GetlDslTest {
    @Test
    void testProc1() {
        Getl.Dsl {
            callScripts data.ConnectToVertica

            verticaConnection('ver:con').retrieveDatasets(schemaName: 'demo') { table ->
                table.truncate()
            }

            callScript proc.Proc1

            verticaConnection('ver:con').retrieveDatasets(schemaName: 'demo') { table ->
                assertTrue(table.countRows() > 0)
            }
        }
    }
} 
```
* _callScripts_ только один раз вызывает указанный скрипт. Если в Proc1 тоже вызывается этот скрипт через _callScripts_,
то он не будет вызван второй раз. Это гарантирует, что не будет второй попытки зарегистрировать соединение Vertica в 
репозитории.
* При запуске сценариев в _GetlDslTest_ классе, для них будет установлена среда выполнения dev. Так же внутри сценариев
сработает блок ifUnitTestMode, в котором можно описать логику работы сценария при запуске в таком режиме.
* При вызове разных @Test методов в классе, конфигурация и репозиторий Getl не будут очищаться. Если для каждого метода
тест класса нужна чистая среда, то можно воспользоваться вызовом _CleanGetl_, указав его в @Before.
  
# В заключение про Getl
Несмотря на приличный объем статьи, здесь описана только небольшая часть того, что умеет Getl.

Примеры работы с его классами и Dsl языком можно найти в юнит тестах самого проекта Getl. Небольшой пример проекта ХД на
H2 можно посмотреть на проекте GitHub [Getl examples](https://github.com/ascrus/getl-examples).

